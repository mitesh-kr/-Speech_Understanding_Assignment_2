# ################################
# Model: SepFormer for source separation + WavLM Speaker Classification
# ################################

seed: 1
__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]


# Data params
data_folder: /yourpath/whamr
base_folder_dm: /yourpath/wsj0-processed/si_tr_s/

experiment_name: "SepFormer_WavLM_Separation_Classification"
output_folder: /iitjhome/m23mac004/ZZZZZ/SepFormer_WavLM_Separation_Classification/1

train_log: !ref <output_folder>/train_log.txt
save_folder: !ref <output_folder>/save

metrics_dir: "/iitjhome/m23mac004/ZZZZZ/SepFormer_WavLM_Separation_Classification"
metrics_file: !ref <metrics_dir>/TRAINING_METRICS_<seed>.csv

train_data: /iitjhome/m23mac004/ZZZZZ/4/train_mixed_source_class.csv
skip_prep: False


# Experiment params
precision: fp16  # bf16, fp16 or fp32
num_spks: 2
save_audio: True  # Save estimated sources on disk
sample_rate: 8000

# Classification Parameters
use_classifier: True
num_speakers: 50
classification_weight: 0.1  
classify_during_training: True

# Additional separation loss weights
l2_loss_weight: 0.2        # Weight for L2 waveform loss
perceptual_loss_weight: 0.3  # Weight for STFT-based perceptual loss

# WavLM classifier params 
wavlm_sample_rate: 16000
fixed_duration: 4.0  # seconds
embedding_size: 512
lora_rank: 4  # Increased from 8
lora_alpha: 8  # Increased from 16
lora_dropout: 0.2  # Slightly increased
arcface_margin: 0.2  # Reduced from 0.3
arcface_scale: 64  # Increased from 30

classifier_checkpoint: null 

####################### Training Parameters ####################################
N_epochs: 100
batch_size: 1
lr: 0.001
clip_grad_norm: 1.0
loss_upper_lim: 999999 
limit_training_signal_len: False
training_signal_len: 32000000

dynamic_mixing: False
gradient_accumulation: 4 
# Parameters for data augmentation
# Augmentation
# Reverb
rir_path: /iitjhome/m23mac004/ZZZZZ/4/whamr_rirs

use_wavedrop: False
use_speedperturb: True
use_rand_shift: False
min_shift: -8000
max_shift: 8000

# Speed perturbation
speed_changes: [95, 100, 105]
speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb
    orig_freq: !ref <sample_rate>
    speeds: !ref <speed_changes>

# Frequency drop
drop_freq_low: 0
drop_freq_high: 1
drop_freq_count_low: 1
drop_freq_count_high: 3
drop_freq_width: 0.05

drop_freq: !new:speechbrain.augment.time_domain.DropFreq
    drop_freq_low: !ref <drop_freq_low>
    drop_freq_high: !ref <drop_freq_high>
    drop_freq_count_low: !ref <drop_freq_count_low>
    drop_freq_count_high: !ref <drop_freq_count_high>
    drop_freq_width: !ref <drop_freq_width>

# Time drop
drop_chunk_count_low: 1
drop_chunk_count_high: 5
drop_chunk_length_low: 1000
drop_chunk_length_high: 2000

drop_chunk: !new:speechbrain.augment.time_domain.DropChunk
    drop_length_low: !ref <drop_chunk_length_low>
    drop_length_high: !ref <drop_chunk_length_high>
    drop_count_low: !ref <drop_chunk_count_low>
    drop_count_high: !ref <drop_chunk_count_high>

threshold_byloss: True
threshold: -30

# Encoder parameters
# N_encoder_out: 256
# out_channels: 256
# kernel_size: 16
# kernel_stride: 8

N_encoder_out: 128
out_channels: 128
kernel_size: 16
kernel_stride: 8

# Dataloader options
dataloader_opts:
    batch_size: !ref <batch_size>
    num_workers: 0
    pin_memory: False
    shuffle: True

# Specifying the separation network
Encoder: !new:speechbrain.lobes.models.dual_path.Encoder
    kernel_size: !ref <kernel_size>
    out_channels: !ref <N_encoder_out>

SBtfintra: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock
    num_layers: 8
    d_model: !ref <out_channels>
    nhead: 8
    d_ffn: 1024
    dropout: 0
    use_positional_encoding: True
    norm_before: True

SBtfinter: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock
    num_layers: 8
    d_model: !ref <out_channels>
    nhead: 8
    d_ffn: 1024
    dropout: 0
    use_positional_encoding: True
    norm_before: True

MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model
    num_spks: !ref <num_spks>
    in_channels: !ref <N_encoder_out>
    out_channels: !ref <out_channels>
    num_layers: 2
    K: 250
    intra_model: !ref <SBtfintra>
    inter_model: !ref <SBtfinter>
    norm: ln
    linear_layer_after_inter_intra: False
    skip_around_intra: True

Decoder: !new:speechbrain.lobes.models.dual_path.Decoder
    in_channels: !ref <N_encoder_out>
    out_channels: 1
    kernel_size: !ref <kernel_size>
    stride: !ref <kernel_stride>
    bias: False


wavlm_classifier: !new:WAVLM_LORA_ARC.WavLMSpeakerClassifier
wavlm_classifier: !new:wavlm_lora_arc.WavLMSpeakerClassifier
  num_classes: !ref <num_speakers>
  base_model_path: "microsoft/wavlm-base-plus"
  config: !new:WAVLM_LORA_ARC.SpeakerClassificationConfig
    LORA_RANK: !ref <lora_rank>
    LORA_ALPHA: !ref <lora_alpha>
    LORA_DROPOUT: !ref <lora_dropout>
    ARCFACE_MARGIN: !ref <arcface_margin>
    ARCFACE_SCALE: !ref <arcface_scale>
    
# Loss functions
separation_loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper
classification_loss: !name:torch.nn.CrossEntropyLoss

# Optimizer
optimizer: !name:torch.optim.AdamW
    lr: !ref <lr>
    weight_decay: 0.01

# Learning rate scheduler
lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau
    factor: 0.5      # Reduce learning rate by half when plateaued
    patience: 3      # Wait for 3 epochs with no improvement
    dont_halve_until_epoch: 50  # Start potentially reducing LR earlier

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <N_epochs>

modules:
    encoder: !ref <Encoder>
    decoder: !ref <Decoder>
    masknet: !ref <MaskNet>
    wavlm_classifier: !ref <wavlm_classifier>



# Change this in your YAML file
save_all_checkpoints: True  # Make sure this is set to True
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        encoder: !ref <Encoder>
        decoder: !ref <Decoder>
        masknet: !ref <MaskNet>
        wavlm_classifier: !ref <wavlm_classifier>
        counter: !ref <epoch_counter>
        lr_scheduler: !ref <lr_scheduler>

# Logging - Replace wandb logger with file logger
train_logger: !ref <file_logger>

file_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

tensorboard_logger: !new:speechbrain.utils.train_logger.TensorboardLogger
    save_dir: !ref <output_folder>